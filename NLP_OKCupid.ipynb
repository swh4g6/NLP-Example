{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction, NLP and Naive-Bayes: OKCupid Profiles\n",
    "\n",
    "## Introduction:\n",
    "This project analyzes data from the online dating application, OKCupid, that is a summary of profile information from users in the San Francisco Bay Area. The goal is to scope, prep, analyze/extract features and create a machine learning model to answer a question:\n",
    "Can you predict if someone works in a STEM (Science, Technology, Engineering and Math) profession based on their user profile data?\n",
    "\n",
    "**Data sources:**\n",
    "\n",
    "`profiles.csv` was provided by Codecademy.com with permission from OKCupid.\n",
    "\n",
    "## Scope:\n",
    "### Project Goal\n",
    "The goal is to use exploratory data analysis to identify potential features of OKCupid profiles that may help predict whether or not an individual works in the STEM field. I will then use these features to build and evaluate a Naive-Bayes model. This will demonstrate and exercise skills in data cleaning, feature extraction, natural language processing and model evaluation.\n",
    "### Data\n",
    "The project has one data set provided by Codecademy called profiles.csv. In the data, each row represents an OkCupid user and the columns are the responses to their user profile questions, which include multiple-choice and short answer questions. It consists of a mixture of numerical, categorical and free-text variables. I will be focusing on the free-text variables for this example.\n",
    "### Analysis\n",
    "I will use natural language processing to find key terms that will most likely provide significant predictive power for a Naive-Bayes model. \n",
    "### Evaluation\n",
    "Model performance will be initially evaluated based on Area Under the Receiver Operating Characteristic Curve (ROC AUC). The final model will also be evaluated based on accuracy score and confusion matrix statistics with a discussion on how to select a threshold based on profit-matrix values.\n",
    "\n",
    "## Load General Libraries and Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   essay0       54458 non-null  object \n",
      " 7   essay1       52374 non-null  object \n",
      " 8   essay2       50308 non-null  object \n",
      " 9   essay3       48470 non-null  object \n",
      " 10  essay4       49409 non-null  object \n",
      " 11  essay5       49096 non-null  object \n",
      " 12  essay6       46175 non-null  object \n",
      " 13  essay7       47495 non-null  object \n",
      " 14  essay8       40721 non-null  object \n",
      " 15  essay9       47343 non-null  object \n",
      " 16  ethnicity    54266 non-null  object \n",
      " 17  height       59943 non-null  float64\n",
      " 18  income       59946 non-null  int64  \n",
      " 19  job          51748 non-null  object \n",
      " 20  last_online  59946 non-null  object \n",
      " 21  location     59946 non-null  object \n",
      " 22  offspring    24385 non-null  object \n",
      " 23  orientation  59946 non-null  object \n",
      " 24  pets         40025 non-null  object \n",
      " 25  religion     39720 non-null  object \n",
      " 26  sex          59946 non-null  object \n",
      " 27  sign         48890 non-null  object \n",
      " 28  smokes       54434 non-null  object \n",
      " 29  speaks       59896 non-null  object \n",
      " 30  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# load profile data\n",
    "profiles = pd.read_csv('profiles.csv', encoding='utf-8')\n",
    "\n",
    "profiles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay8    32.07\n",
      "essay6    22.97\n",
      "essay9    21.02\n",
      "essay7    20.77\n",
      "essay3    19.14\n",
      "essay5    18.10\n",
      "essay4    17.58\n",
      "essay2    16.08\n",
      "job       13.68\n",
      "essay1    12.63\n",
      "essay0     9.15\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   essay0  54458 non-null  object\n",
      " 1   essay1  52374 non-null  object\n",
      " 2   essay2  50308 non-null  object\n",
      " 3   essay3  48470 non-null  object\n",
      " 4   essay4  49409 non-null  object\n",
      " 5   essay5  49096 non-null  object\n",
      " 6   essay6  46175 non-null  object\n",
      " 7   essay7  47495 non-null  object\n",
      " 8   essay8  40721 non-null  object\n",
      " 9   essay9  47343 non-null  object\n",
      " 10  job     51748 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe based on columns associated with free-text or the target variable\n",
    "profiles_text = profiles[['essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', \n",
    "                          'essay6', 'essay7', 'essay8', 'essay9', 'job']]\n",
    "\n",
    "# helper method to quantify percentage of missingness\n",
    "def percent_missing(df):\n",
    "    print((100*df.isna().sum().sort_values(ascending=False)/len(df)).round(2))\n",
    "    \n",
    "# show missing percents    \n",
    "percent_missing(profiles_text)\n",
    "profiles_text.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary:\n",
    "Profiles_text consists of 11 columns and 59946 rows. Column content and missingness are discussed below.\n",
    "\n",
    "**The columns in the dataset include:**\n",
    "- job: nominal variable of employment description (will convert to binary target, STEM = 1 and Other = 0)\n",
    "\n",
    "**And a set of open short-answer responses to :**\n",
    "- essay0: My self summary\n",
    "- essay1: What I’m doing with my life\n",
    "- essay2: I’m really good at\n",
    "- essay3: The first thing people usually notice about me\n",
    "- essay4: Favorite books, movies, show, music, and food\n",
    "- essay5: The six things I could never do without\n",
    "- essay6: I spend a lot of time thinking about\n",
    "- essay7: On a typical Friday night I am\n",
    "- essay8: The most private thing I am willing to admit\n",
    "- essay9: You should message me if…\n",
    "\n",
    "**Percent of Missingness by Column:**\n",
    "    \n",
    "     essay8      32.07\n",
    "     essay6      22.97\n",
    "     essay9      21.02\n",
    "     essay7      20.77\n",
    "     essay3      19.14\n",
    "     essay5      18.10\n",
    "     essay4      17.58\n",
    "     essay2      16.08\n",
    "     job         13.68\n",
    "     essay1      12.63\n",
    "     essay0      9.15\n",
    "     \n",
    "     \n",
    "## Data Exploration, Transformation and Feature Extraction:\n",
    "### Creating the Target\n",
    "All rows with a null value for 'essay0' or 'job' were dropped leaving 47,489 total. A new column was created to represent the target variable for STEM jobs. Any users that answered 'science / tech / engineering', 'computer / hardware / software', or 'medicine / health' were considered to work in the STEM field. The target class represents ~25.6% of the sample, which means it is moderately imbalanced. If I downsample the non-STEM examples, there will be a loss of data about non-STEM users that could potentially hurt the model performance. Conversely, oversampling the minority can lead to overfitting and poor future performance of the model. During model training, various techniques for oversampling the miniority class (SMOTE, BorderlineSMOTE, SMOTEN) and undersampling (RandomUnderSampling) the majority class will be empirically evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47489\n",
      "0.2567120806923709\n"
     ]
    }
   ],
   "source": [
    "# drop any rows with null values for essay0, which will guarantee some free-text data for each row\n",
    "profiles_text = profiles_text[profiles_text['essay0'].notna()].reset_index()\n",
    "\n",
    "# drop any rows with null values for job\n",
    "profiles_text = profiles_text[profiles_text['job'].notna()].reset_index()\n",
    "\n",
    "# check new length of dataframe (OUTPUT: 51748)\n",
    "print(len(profiles_text))\n",
    "\n",
    "# create a list of values for STEM field jobs\n",
    "STEM_list = ['science / tech / engineering', 'computer / hardware / software', 'medicine / health']\n",
    "\n",
    "# create new column 'STEM' to hold binary target variable. 1 = STEM field job\n",
    "profiles_text['STEM'] = profiles_text.apply(lambda row: 1 if row['job'] in STEM_list else 0, axis=1)\n",
    "\n",
    "# check for target class balance\n",
    "print(profiles_text.STEM.sum()/len(profiles_text))\n",
    "# target is about 25.6%, which is moderately imbalanced. Consider resampling STEM jobs or downsampling non-STEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Prepping for Analysis\n",
    "\n",
    "## Natural Language Processing:\n",
    "### Preprocessing Text\n",
    "1. Import libraries from nltk, the Natural Language Toolkit.\n",
    "2. Collect document column names into a list.\n",
    "3. Replace null documents with empty strings.\n",
    "4. Convert text to lowercase and remove punctuation. \n",
    "5. Combine all text columns into one column, the corpus with each row representing a document.\n",
    "\n",
    "At this point the number of unique words in the corpus was exceptionally large, 148,517 as seen with value_counts(). The more common a word in the corpus, the less predictive power it will have. Also, if it is too rare, the word will not be prevalent enough to train the model. A threshold of at least 50 occurrences in the corpus was chosen as a minimum. Additionally, the 100 most common words were eliminated as stop words. This reduced the corpus vocabulary to 13,507 words, which is much more manageable. To save on processing time, a whitelist of the 13,507 word vocabulary was used. A stop_word list was ten times as long and would have taken roughly ten times the processing time. \n",
    "\n",
    "6. Remove common and rare words.\n",
    "7. Split document into word tokens.\n",
    "8. Lemmatize word tokens by converting words to their common root. Most accurate when done with the words part of speech. An example: 'are', 'is' and 'will' become 'be' after lemmatization. This helps reduce the overall vocabulary size.\n",
    "\n",
    "**Note:** Steps 4 and 6-8 could have been handled by CountVectorizer() with default/custom settings for stop_words and lemmatization with a smaller collection of data. With one this size, I received a memory usage error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries for NLP\n",
    "import nltk, re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# create list of essay columns\n",
    "essays = ['essay0', 'essay1', 'essay2', 'essay3', 'essay4',\\\n",
    "          'essay5', 'essay6', 'essay7', 'essay8', 'essay9']\n",
    "\n",
    "# fill in null essays with empty strings\n",
    "profiles_text[essays] = profiles_text[essays].replace(np.nan, '', regex= True)\n",
    "\n",
    "# convert all text to lowercase, remove punctuation\n",
    "for essay in essays:\n",
    "    profiles_text[essay] = profiles_text[essay].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    profiles_text[essay] = profiles_text[essay].str.replace('[^\\w\\s]',' ', regex=True)\n",
    "\n",
    "# combine all essay column text in a new column 'all_essays'\n",
    "profiles_text['all_essays'] = profiles_text[essays].apply(lambda x: ' '.join(x), axis= 1)\n",
    "\n",
    "# find somewhat common words (occurence rate of >50, but not the 100 most common in corpus)\n",
    "white_list_words = pd.Series(' '.join(profiles_text['all_essays'])\\\n",
    "                                .split()).value_counts()[100:]\\\n",
    "                                .loc[lambda x: x > 50].index.tolist()\n",
    "\n",
    "# this step is resource intensive. checks each word in all_essays against the whitelist of 13507.\n",
    "# a stopword list with the 100 most frequent and the words with term frequencies < 50 was 135010 terms long.\n",
    "# in this case, checking against a white list is 10x faster\n",
    "profiles_text['all_essays'] = profiles_text['all_essays'].apply(lambda x: ' '.join(x for x in x.split() if x in white_list_words))\n",
    "\n",
    "# create a lemmatizer object\n",
    "normalizer = WordNetLemmatizer()\n",
    "\n",
    "# helper method to retrieve most likely part of speech for a word\n",
    "def get_part_of_speech(word):\n",
    "    # retrieve parts of speech from wordnet.synsets()\n",
    "    probable_part_of_speech = wordnet.synsets(word)\n",
    "    \n",
    "    # create counter object\n",
    "    pos_counts = Counter()\n",
    "    \n",
    "    # count parts of speech\n",
    "    pos_counts['n'] = len([item for item in probable_part_of_speech if item.pos()=='n'])\n",
    "    pos_counts['v'] = len([item for item in probable_part_of_speech if item.pos()=='v'])\n",
    "    pos_counts['a'] = len([item for item in probable_part_of_speech if item.pos()=='a'])\n",
    "    pos_counts['r'] = len([item for item in probable_part_of_speech if item.pos()=='r'])\n",
    "    \n",
    "    # assign part of speech to the most common\n",
    "    most_likely_part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "    \n",
    "    return most_likely_part_of_speech\n",
    "\n",
    "# helper method to preprocess text and return a lemmatized list of words\n",
    "def preprocess_text(text):\n",
    "    # remove non-word characters and spaces, convert to lower-case\n",
    "    cleaned = re.sub(r'\\W+', ' ', text).lower()\n",
    "    # create a tokenized list of words\n",
    "    tokenized = word_tokenize(text)\n",
    "    # lemmatize tokenized list with the part of speech fed to the lemmatizer\n",
    "    normalized = \" \".join([normalizer.lemmatize(token, get_part_of_speech(token)) for token in tokenized])\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "# tokenize and lemmatize the words in all_essays\n",
    "profiles_text['all_essays'] = profiles_text.apply(lambda row: preprocess_text(row['all_essays']), axis= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Keywords by Odds-Ratios Adjusted for False Discovery Rate Between STEM and nonSTEM Profiles\n",
    "\n",
    "The goal of this processing is to extract keywords that are particularly associated with one class over another using an odds-ratio. If the words are equally associated with each class the ratio is one. The higher above one, the more closely it is associated with STEM words. The closer the ratio gets to 0, the more it is associated with nonSTEM profiles.\n",
    "\n",
    "1. The profiles are divided based on the target variable.\n",
    "2. The CountVectorizer is used in binary mode to return if a vocabulary word is found in a user's combined essays document.\n",
    "3. This information is stored in a dataframe by each class.\n",
    "4. The binary row for each word is summed for the class. This equates to the number of profiles where that word occurs.\n",
    "5. The number from step 4 is subtracted from the total number of class profiles. This is the number of profiles that did not have that word.\n",
    "6. The dataframes for each class are combined using an inner join on the indexes (words).\n",
    "7. Between class odds-ratios and p-values for each word are computed with Fisher's exact test method from Scipy.stats.\n",
    "8. Because this is a test run thousands of times, there is a large risk of false-positives accumulating. To counteract a high false-positive rate, Benjamani-Hochberg correction for p-values was applied.\n",
    "9. A cutoff of a corrected p-value less than 1.0 x 10^-6 and an odds ratio greater than 2 or less than 0.5 was chosen to limit the keyword selection.\n",
    "\n",
    "**Interpretation:** Words where the interclass odds-ratio is greater than 2 indicate these words are at least twice as likely to occur in a STEM profile. Words where the interclass odds-ratio is less than 0.5 are twice as likely to occur in a non-STEM profile. A corrected p-value less than 1.0 x 10^-6 means that the probability of these odds-ratios occuring by chance alone are less than one in a million.\n",
    "\n",
    "**This 2x odds-ratio cutoff yielded 120 terms found in the lists below:**\n",
    "\n",
    "    104 STEM words:\n",
    "     \n",
    "    '_blank',        'algorithm',      'alto',           'anathem',         'android',  \n",
    "    'application',   'apps',           'artificial',     'asimov',          'bicycling', \n",
    "    'biomedical',    'biotech',        'bt',             'canada',          'clinic', \n",
    "    'clinical',      'cod',            'code',           'commute',         'computer', \n",
    "    'computing',     'coworkers',      'crossfit',       'cryptonomicon',   'data', \n",
    "    'database',      'developer',      'dna',            'electrical',      'electronics', \n",
    "    'emergency',     'ender',          'engineer',       'engineering',     'escher', \n",
    "    'feynman',       'fm',             'freakonomics',   'gadget',          'gattaca', \n",
    "    'geeky',         'gibson',         'hack',           'hacker',          'hardware', \n",
    "    'healthcare',    'heinlein',       'hospital',       'iain',            'intp',            \n",
    "    'javascript',    'lab',            'laser',          'linux',           'mechanical',      \n",
    "    'medical',       'mit',            'mobile',         'molecular',       'neal',            \n",
    "    'neuromancer',   'neuroscience',   'nofollow',       'nurse',           'orbital',         \n",
    "    'palo',          'pediatric',      'pharmaceutical', 'physician',       'practitioner',    \n",
    "    'pratchett',     'primer',         'programmer',     'programming',     'psychotherapist', \n",
    "    'register',      'rel',            'researcher',     'residency',       'rn',             \n",
    "    'scientific',    'scientist',      'scifi',          'silicon',         'software',        \n",
    "    'solar',         'soma',           'startup',        'stephenson',      'stross',       \n",
    "    'tech',          'techie',         'technical',      'technician',      'technology',     \n",
    "    'therapist',     'tinker',         'ucsf',           'ui',              'vernor',        \n",
    "    'vinge',         'web',            'wikipedia',      'xkcd'\n",
    "        \n",
    "It appears to be a success. STEM words are associated with STEM professions, like 'rn' for Registered Nurse or 'developer'. They also play to popculture stereotypes. For example, STEM users talk about Neal Stephenson's books \"Anathem\" and \"Cryptonomicon\" and Sci-Fi authors Vernor Vinge and Charles Stross. They also mention noted physicist Richard Feynman and my personal favorite science themed webcomic, 'XKCD'. For exercise, they seem to enjoy 'bicycling' and 'crossfit'. \n",
    "\n",
    "    16 non-STEM words:\n",
    "     \n",
    "    'accounting',    'attorney',       'ba',           'credential', \n",
    "    'educator',      'elementary',     'homework',     'lawyer', \n",
    "    'mfa',           'nanny',          'retail',       'semester', \n",
    "    'sfsu',          'student',        'stylist',      'teacher'\n",
    "    \n",
    "\n",
    "\n",
    "Many nonSTEM profiles refer to nonSTEM professions, like 'attorney', 'accounting', 'nanny' and 'hairstylist'. They also refer to Arts education majors like 'BA' and 'MFA'. They also might still be a 'student' at 'SFSU'. \n",
    "\n",
    "Keywords associated with pop-culture will shift in prevalence with the changing popularity of topics in the populace. So while they are a good indicator for this data and time period, they will need to be reupdated if the model is to be used over time. The profession associated words will likely remain a more stable predictor in the long run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# create subset of only STEM profiles and a document collection of only STEM profile essays\n",
    "STEM_data = profiles_text[profiles_text['STEM'] == 1]\n",
    "STEM_text_data = STEM_data['all_essays']\n",
    "\n",
    "# store number of STEM profiles for future calculations\n",
    "num_STEM = len(STEM_data)\n",
    "# create column headers for a dataframe to hold STEM profile binary-word counts. P=positive target class.\n",
    "STEM_profiles = [f\"P {i+1}\" for i in range(num_STEM)]\n",
    "\n",
    "# create a CountVectorizer object in binary mode. Fit_transform on STEM_text_data\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "STEM_vectors = vectorizer.fit_transform(STEM_text_data)\n",
    "\n",
    "# get the feature_names to act as row indexes in STEM_counts dataframe\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# transform the sparse matrix result from the CountVectorizer into a dataframe. \n",
    "# Rows= words, Columns= each profile, Values= binary for each term\n",
    "STEM_counts = pd.DataFrame(STEM_vectors.T.todense(), index=feature_names, columns=STEM_profiles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create STEM_sum_pos column that is the number of STEM profiles that used a word\n",
    "STEM_counts['STEM_sum_pos'] = STEM_counts.apply(lambda x: np.sum(x[STEM_profiles]), axis=1)\n",
    "\n",
    "# create STEM_sum_neg column that is the number of STEM profiles that did not use a word\n",
    "STEM_counts['STEM_sum_neg'] = num_STEM - STEM_counts['STEM_sum_pos']\n",
    "\n",
    "# create nonSTEM subset and document collection\n",
    "nonSTEM_data = profiles_text[profiles_text['STEM'] == 0]\n",
    "nonSTEM_text_data = nonSTEM_data['all_essays']\n",
    "\n",
    "# store number of nonSTEM profiles for future calculations\n",
    "num_nonSTEM = len(nonSTEM_data)\n",
    "\n",
    "# create column headers. N= negative target class\n",
    "nonSTEM_profiles = [f\"N {i+1}\" for i in range(num_nonSTEM)]\n",
    "\n",
    "# transform nonSTEM_text_data with previously fit CountVectorizer object\n",
    "nonSTEM_vectors = vectorizer.transform(nonSTEM_text_data)\n",
    "\n",
    "# create nonSTEM dataframe from previous steps sparse matrix results. Same structure as STEM_counts\n",
    "nonSTEM_counts = pd.DataFrame(nonSTEM_vectors.T.todense(), index= feature_names, columns= nonSTEM_profiles) \n",
    "\n",
    "# create nonSTEM_sum_pos column\n",
    "nonSTEM_counts['nonSTEM_sum_pos'] = nonSTEM_counts.apply(lambda x: np.sum(x[nonSTEM_profiles]), axis=1)\n",
    "\n",
    "# create nonSTEM_sum_neg column\n",
    "nonSTEM_counts['nonSTEM_sum_neg'] = num_nonSTEM - nonSTEM_counts['nonSTEM_sum_pos']\n",
    "\n",
    "# combine class dataframes into one using an innerjoin on indexes\n",
    "all_counts = STEM_counts.merge(nonSTEM_counts, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fisher_exact for computing odds-ratios and p-values\n",
    "from scipy.stats import fisher_exact\n",
    "# import multipletests to calculate adjusted p-values\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# helper method to run fisher's exact test\n",
    "def odds_ratio(class1_pos, class2_pos, class1_neg, class2_neg):\n",
    "    odds_ratio, p_value = fisher_exact([[class1_pos, class2_pos],\n",
    "                                        [class1_neg, class2_neg]])\n",
    "    return odds_ratio, p_value\n",
    "\n",
    "# store odds_ratio in column\n",
    "all_counts['odds_ratio'] = all_counts.apply(lambda x: odds_ratio(x['STEM_sum_pos'], x['nonSTEM_sum_pos'],\n",
    "                                                                 x['STEM_sum_neg'], x['nonSTEM_sum_neg'])[0], axis=1)\n",
    "# store unadjusted p-values in column\n",
    "all_counts['odds_p_value'] = all_counts.apply(lambda x: odds_ratio(x['STEM_sum_pos'], x['nonSTEM_sum_pos'],\n",
    "                                                                 x['STEM_sum_neg'], x['nonSTEM_sum_neg'])[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to calculate and return adjusted p-value\n",
    "def corrected_pval(p_values):\n",
    "    rej, pvals, aSidak, aBonf = multipletests(p_values, alpha=.05, method='fdr_bh')\n",
    "    \n",
    "    return pvals\n",
    "\n",
    "# store corrected p-value in new column\n",
    "all_counts['FDR_corrected_p_value'] = corrected_pval(all_counts['odds_p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 ['_blank', 'algorithm', 'alto', 'anathem', 'android', 'application', 'apps', 'artificial', 'asimov', 'bicycling', 'biotech', 'bt', 'canada', 'clinic', 'clinical', 'cod', 'code', 'commute', 'computer', 'computing', 'coworkers', 'crossfit', 'cryptonomicon', 'data', 'database', 'developer', 'dna', 'electrical', 'electronics', 'emergency', 'engineer', 'engineering', 'escher', 'feynman', 'fm', 'freakonomics', 'gadget', 'gattaca', 'geeky', 'gibson', 'hack', 'hacker', 'hardware', 'healthcare', 'heinlein', 'hospital', 'iain', 'intp', 'javascript', 'lab', 'laser', 'linux', 'mechanical', 'medical', 'mit', 'mobile', 'molecular', 'neal', 'neuromancer', 'neuroscience', 'nofollow', 'nurse', 'orbital', 'palo', 'paramedic', 'pediatric', 'pharmaceutical', 'physician', 'practitioner', 'pratchett', 'primer', 'programmer', 'programming', 'psychotherapist', 'register', 'rel', 'researcher', 'residency', 'rn', 'scientific', 'scientist', 'scifi', 'silicon', 'singularity', 'software', 'solar', 'solve', 'soma', 'startup', 'stephenson', 'stross', 'tech', 'techie', 'technical', 'technician', 'technology', 'therapist', 'tinker', 'ucsf', 'ui', 'vinge', 'web', 'wikipedia', 'xkcd']\n",
      "16 ['accounting', 'attorney', 'ba', 'credential', 'educator', 'elementary', 'homework', 'lawyer', 'mfa', 'nanny', 'retail', 'semester', 'sfsu', 'student', 'stylist', 'teacher']\n"
     ]
    }
   ],
   "source": [
    "# store keywords in two lists based on class affinity.\n",
    "STEM_words = all_counts[(all_counts['FDR_corrected_p_value'] < 0.000001) & (all_counts['odds_ratio'] > 2)].index.tolist()\n",
    "nonSTEM_words = all_counts[(all_counts['FDR_corrected_p_value'] < 0.000001) & (all_counts['odds_ratio'] < .5)].index.tolist()\n",
    "\n",
    "# print length of the lists and the keywords associated with each\n",
    "print(len(STEM_words), STEM_words)\n",
    "print(len(nonSTEM_words), nonSTEM_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Binary Features for Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine lists for keywords\n",
    "keywords = STEM_words + nonSTEM_words\n",
    "\n",
    "# helper method to check if a word is in the profiles essays\n",
    "def get_keyword_binary(keyword, essay_str):\n",
    "    if keyword in essay_str:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# loop through keyword list and create a new binary column of that word in essays\n",
    "for keyword in keywords:\n",
    "    profiles_text[keyword] = profiles_text.apply(lambda row: get_keyword_binary(keyword, row['all_essays']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Plan:\n",
    "\n",
    "The data will be split into training (0.8) and test set (0.2) portions. Using 5-fold cross-validation, keyword features will be run through a Naive-Bayes model. ROC-AUC scores will be computed for each k-fold and the overall average ROC-AUC score will be used for evaluation. ROC-AUC is used because it is a good indicator of overall model performance, independent of the threshold used for classification. Accuracy is not the best statistic because it would be heavily affected by the threshold. \n",
    "\n",
    "Finally, the resultant best model will be scored on the test data to see how training with cross-validation for the model might perform with new samples, indicating future performance.\n",
    "\n",
    "**Note:** Not rebalancing the classes and various methods of oversampling the minority class, undersampling the majority class or a combination of over/undersampling were tried. For oversampling, variations of Synthetic Minority Oversampling Technique (SMOTE) were used from the imbalanced-learning (imblearn) library. For undersampling, Random Under Sampling was used. Based on a comparison of ROC-AUC scores in the test data, not resampling performed the best empirically and was chosen for model fitting. It was also the only method to perform with a ROC-AUC over 0.67 with the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "1. Split data into training and test sets.\n",
    "2. Create Naive_Bayes model.\n",
    "3. Split training sets into 5 k-folds for cross validation.\n",
    "4. Evaluate each model with training data based on ROC-AUC.\n",
    "5. Fit on best trial model and run associated test data.\n",
    "6. Evaluate final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73943844 0.73439825 0.71608594 0.73536559 0.73587263] 0.7322321704951167\n"
     ]
    }
   ],
   "source": [
    "# import tools for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# split into X data and y labels\n",
    "X = profiles_text[keywords]\n",
    "y = profiles_text['STEM']\n",
    "\n",
    "\n",
    "# train test split with 0.2 test portion. random_state set to allow for tuning comparisons.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# create ComplementNB() model. Using this Naive_Bayes model because it is suited to imbalanced class problems.\n",
    "cnb = ComplementNB()\n",
    "\n",
    "# create 5 k-folds for cross-validation. random_state set to keep consistency between trials for model type and tuning.\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state= 42)\n",
    "\n",
    "# run cross-validation and store results \n",
    "cv_results = cross_val_score(cnb,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             cv= skf,\n",
    "                             scoring = 'roc_auc')\n",
    "\n",
    "# print each result with the average for all trials\n",
    "print(cv_results, np.mean(cv_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766157947467512\n",
      "[[5749 1326]\n",
      " [1113 1310]]\n",
      "0.7432090966519267\n",
      "(array([0.83780239, 0.4969651 ]), array([0.81257951, 0.54065208]), array([0.82499821, 0.51788891]), array([7075, 2423], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# fit model and store predictions\n",
    "predictions = cnb.fit(X_train, y_train)\n",
    "\n",
    "# run model on test data\n",
    "predictions = cnb.predict(X_test)\n",
    "\n",
    "# print summary of results\n",
    "print(roc_auc_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(precision_recall_fscore_support(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results: \n",
    "\n",
    "**Training Data:** \n",
    "\n",
    "- ROC-AUC Cross Validation = 0.73943844, 0.73439825, 0.71608594, 0.73536559, 0.73587263\n",
    "- ROC-AUC Average = 0.7322321704951167\n",
    "\n",
    "**Test Data:** \n",
    "\n",
    "- ROC-AUC = 0.6766157947467512\n",
    "- Accuracy = 0.7432090966519267\n",
    "- Confusion Matrix = \n",
    "                        \n",
    "                              PREDICTED\n",
    "                        | nonSTEM | STEM |\n",
    "       ACTUAL | nonSTEM |    5749 | 1326 |\n",
    "              |    STEM |    1113 | 1310 |\n",
    "\n",
    "\n",
    "- STEM precision = 0.4969651 \n",
    "- STEM recall = 0.54065208\n",
    "- STEM F1 = 0.51788891\n",
    "- Test data num_STEM (support) = 2423\n",
    "\n",
    "- nonSTEM precision = 0.83780239\n",
    "- nonSTEM recall = 0.81257951\n",
    "- nonSTEM F1 = 0.82499821\n",
    "- Test data num_nonSTEM (support) = 7075\n",
    "\n",
    "## Interpretation:\n",
    "\n",
    "In general, ROC-AUC scores of 0.7-0.8 are considered acceptable. Performance on the test data was just under this threshold. For context, a score of 0.5 is indicative of random guessing for equally distributed classes and a score of 1 is a perfect model. The cross-validation model performance with only the keyword data features indicates the value of information that can be derived from free-text sources.\n",
    "\n",
    "Looking at the test data confusion matrix and by class statistics, this model does not necessarily predict STEM profiles well, but performs well in predicting non-STEM profiles. Overall, the errors are most likely due to the amount of missing information in the original data and the fact that the test data classes were not rebalanced. In this case the model derives its prediction from the free-text data, and many profiles did not fill out all of the essays. As such, when computing probability of class, the model has limited information and was more often correct in the test data when assigning non-STEM due to a class imbalance in the population. A random guess between classes is more likely to be correct if it is non-STEM because the population occurrence of non-STEM profiles is roughly 3:1. The frequency of error types could be adjusted by lowering or raising the threshold of prediction for STEM profiles. Normally this would be done with the use of a profit-matrix where a different penalty (increased risk or financial cost) is assigned to the two types of error, false-positives and false-negatives. Based on the cost of each type of error, the decision threshold would be adjusted to shift the balance of the errors towards the less costly type.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "This was a good exercise in keyword feature extraction with natural language processing and strategies for dealing with imbalanced target classes. Similar NLP techniques can be used for summarizing or classifying documents, emails, online reviews and free-form responses in surveys. Typically tf-idf vectors from the count-vectorizer are fed into a model, but are difficult to interpret exactly how the model is arriving at its decision. Extracting the odds-ratio and identifying the keywords that are being used allows insight into the method of prediction and can avoid unintentional bias in the real world. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
